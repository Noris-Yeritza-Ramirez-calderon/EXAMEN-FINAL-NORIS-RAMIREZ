---
title: "ANALISIS FACTORIAL"
author: "NORIS YERITZA RAMIREZ CALDERON 1950198"
output: github_document
---


# IMPORTAR LA BASE DE DATOS   
```{r}
library(readxl)
datosd <- read_excel("C:/Users/Lenovo/Desktop/PARCIAL DE DISEÑO/datosfinales.xlsx")
```

# TIPIFICACION O ESTANDARIZACION DE VARIABLES   
La tipificacion permite que todas las variables metricas gocen de una misma unidad de medida estadistica.
```{r}
DatosDDE <- datosd #Crear una nueva base de datos o data frame
DatosDDE <- scale(DatosDDE, center = T, scale = T)
DatosDDE <- as.data.frame(DatosDDE)
```

# NORMALIDAD MULTIVARIANTE  
H0: Normalidad multivariante  
H1: No normalidad multivariante  
Confianza= 95%  
Alfa= 5%= 0,05  
P value es mayor (>) a alfa: No se rechaza la hipotesis nula H0 (Normalidad)  
P value es menor (<) a alfa: Se rechaza la hipotesis nula H0 (No normalidad)  
```{r}
library(MVN)
mvn(DatosDDE[2:7])
```
Como el P value es mayor (>) a alfa, no se rechaza la hipotesis nula H0, por lo tanto, existe normalidad multivariante.

# MATRIZ DE CORRELACIONES    
H0: La correlacion entre las variables es = 0 (No hay correlacion)  
H1: La correlacion es diferente a 0 (Si hay correlacion)  

Cuando no se rechaza la hipotesis nula H0, entonces no se aplica el Analisis Factorial Exprovatorio (AFE).  
```{r}
library(psych)
corr.test(DatosDDE[,2:7])
Correlaciones <- corr.test(DatosDDE[,2:7]) #Se crea la matriz de correlaciones
Correlaciones$r #Esta es la matriz de correlaciones
r <- as.matrix(Correlaciones$r)
```
Af: 0,05  
P value es mayor (>) a alfa: No se rechaza la hipotesis nula H0   
P value es menor (<) a alfa: Se rechaza la hipotesis nula H0, estamos en esta situacion por lo tanto, si es aplicable el Analisis Factorial Exploratorio (AFE).  

# INDICADORES DE APLICABILIDAD DEL AFE (BONDAD DEL AJUSTE)    
## CONTRASTE DE ESFERICIDAD DE BARTLETT      
H0: En las correlaciones teoricas entre cada par de variable es nulo  
H1: Las correlaciones teoricas entre cada par de variables no es nulo  

P value es mayor (>) a alfa: No se aplica el AFE (no se rechaza H0)  
P value es menor (<) a alfa: Si Se aplica el AFE (no se rechaza H1)  
```{r}
dim(DatosDDE) #Tamaño de muestra= 30 personas
cortest.bartlett(r, n= 30)
```
Como el P value es menor a alfa, se rechaza la hipotesis nula H0, por lo tanto, las correlaciones teoricas entre cada par de variables es nulo, es decir, si es aplicable el analisis factorial exploratorio (AFE)  

# MEDIDA DE ADECUACION MUESTRAL DE KAISER, MEYER Y OKLIN (KMO)    
Estudia variables, si son o no aceptadas en el modelo para hacer AFE. (Que variables elimino o mantengo)  
Se mantiene una variable en el modelo, si el KMO es igual o mayor a 0,7.  
Se elimina una variable del modelo, si el KMO es menor a 0,7.  
```{r}
KMO(r)
```
El KMO= 0,58 el modelo es miserable, si es adecuado para realizar analisis factorial.  
KMO edad= 0,51 (Miserable)  
KMO años de estudio= 0,53 (Miserable)  
KMO horas de trabajo= 0,57 (Miserable)  
KMO tiempo libre= 0,59 (Miserable)  
KMO horas que hacen ejercicio= 0,67 (Middling)  
KMO horas en familia= 0,76 (Middling)  

## DETERMINACION DEL NUMERO DE FACTORES A EXTRAER        
## Metodo de las componentes principales iteradas (Ejes principales)  
Este metodo de las Ejes principales es de naturaleza no parametrica, es decir, que se ocupa, cuando no hay normalidad multivariante; pero tambien es valido para modelos parametricos (normalidad multivariante).  
```{r}
fa.parallel(r, "pa", n.obs=30, ylabel="Eigenvalues")
```
Con el metodo de los ejes principales se extraerian solo 2 factores.  

## Metodo de las componentes principales    
Metodo parametrico, sirve solo para modelos con normalidad multivariante.  
```{r}
fa.parallel(r, "pc", n.obs=30, ylabel= "Eigenvalues")
```
Con el metodo de las componentes principales se recomienda extraer 2 factores.  

## Metodo de la maxima verosimilidad  
Metodo parametrico, sirve solo para modelos con normalidad multivariante.  
```{r}
fa.parallel(r, "ml", n.obs=30, ylabel= "Eigenvalues")
```
Con el metodo de la maxima verosimilidad se recomienda extraer 2 factores.  

## Metodo paralelo con iteraciones  
Metodo parametrico, sirve solo para nodelos con normalidad multivariante.  
```{r}
library(paran)
paran(r, iterations= 1000, graph= T)
```
Con el metodo Horn´s (metodo paralelo con iteraciones) se recomienda extraer 2 factores.  

Resumen:  
Ejes principales= 2 factores  
Componentes principales= 2 factores  
Maxima verosimilitud= 2 factores  
Metodo paralelo con iteraciones (Horn´s )= 2 factores  

Conclucion:  
Vamos a extraer 2 factores  

# METODOS DE EXTRACCION DE FACTORES  
## METODO DE ANALISIS DE LOS COMPONENTES PRINCIPALES (ACP)  
```{r}
acp <- principal(r, infactors=1, rotate= "none")
acp
```
PC1: Cargas factoriales de cada variable.  
h2: Comunalidad (Varinza comun explicada).   
- Edad es explicada 38% por el factor extraido.  
- Años de estudio explicada en un 14% por el factor extraido.  
- Horas de trabajo explicada en un 61% por el factor extraido.  
- Tiempo libre (horas) explicada en un 72% por el factor extraido.  
- Horas que hacen ejercicio explicado en un 49% por el factor extraido.  
- Horas en familia explicado en un 30% por un factor extraido.  

Mientras mas alta sea h2 es mejor el modelo. 0;1  

u2: Especificidad (Varianza residual o varianza no aplicada).  
- Edad no es explicado en un 62%.  
- Años pierde 86%.  
- Horas de trabajo pierde 39%.  
- Tiempo libre (horas) pierde 28%.  
- Horas que hacen ejercicio pierde un 51%.  
- Horas en familia pierde 70%.  

Mientras mas pequeño sea u2 es  mejor el modelo. 0;1.  

h2 + u2 = 1  
Comunalidad + Especificidad= 1.    

SS loadings= 2.65 (Es la varinza explicada en valores absolutos, o la suma de los dos h2).    

Proportion Var= 0.44 (El % que la varianza explicada representa el total).  

Lo "ideal" es que proportion var sea lo mas cercano a 1.  

RMSR= 0.26 (Raiz cuadrada media de los residuos)  
Teoricamente un modelo presenta una solucion adecuada cuando el RMSR es menor o igual a 0,26.  

# METODO DE LOS EJES PRINCIPALES O COMPONENTES PRINCIPALES ITERADAS (CPI)  
```{r}
cpi <- fa(r, nfactors=1, fm="pa", rotate="nome", n.obs=30)
cpi
```
Proportion Var= 36%  
RMSR= 0,23  

## METODO DE MAXIMA VEROSIMILITUD (MVE)  
```{r}
mve <- fa(r, nfactors=1, fm="pa", rotate="nome", n.obs=30) 
mve
```
Proportion Var= 36%  
RMSR= 0,23  

### RESUMEN
ACP= var= 44%   RMSR= 0,26    
CPI= var= 36%   RMSR= 0,23    
MVE= var= 36%   RMSR= 0,23    

¿Con cual nos quedamos?    
Aquel modelo que tenga la proportion var mas alta y el RMSR mas pequeño.  

# OBTENCION DE LAS PUNTUACIONES FACTORIALES  
## METODO DE ANALISIS DE LAS COMPONENTES PRINCIPALES ITERADAS (ACP)  
```{r}
acp1 <- principal(DatosDDE[2:7], nfactors=1, rotate="nome", scores= T)
acp1$scores
puntuacionesfactoriales_acp <- acp1$scores
puntuacionesfactoriales_acp <- as.data.frame(puntuacionesfactoriales_acp)
```
## METODO DE LAS COMPONENTES PRINCIPALES ITERADAS (CPI)  
```{r}
cpi1 <- fa(DatosDDE[,7:2], nfactors = 1, fm="pa", rotate="nome", n.obs=30, scores="regression")
cpi1$scores
puntfac_cpi <- cpi1$scores
puntfac_cpi <- as.data.frame(puntfac_cpi)
```
## METODO DE LA MAXIMA VEROSIMILITUD  
```{r}
mve1 <- fa(DatosDDE[,2:7], nfactors = 1, fm="lm", rotate="nome", n.obs=30, scores = "regression")
mve1$scores
puntfac_mve <- mve1$scores
puntfac_mve <- as.data.frame(puntfac_mve)
```
# OBTENCION DE LOS FACTORES EXTRAIDOS  
Aqui se trabaja con el metodo que el investigador decicio (ACP, CPI, MVE).  
```{r}
factor.scores(r, mve, method = "Thurstone")
```
z1=   
- -0,037 edad  
- +0,17 años de estudio  
- -0,30 horas de trabajo 
- +0,54 tiempo libre (horas)  
- +0,15 horas que hacen ejercicio  
- +0,064 horas en familia  

# AGREGAR FACTOR EXTRAIDO (PUNTUACIONES FACTORIALES) EN EL DATA FRAME ORIGINAL  
```{r}
datos_puntuaciones<- c(datosd, puntuacionesfactoriales_acp)
datos_puntuaciones <- as.data.frame((datos_puntuaciones))
```






